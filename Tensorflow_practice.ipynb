{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.Variable(3,name=\"x\")\n",
    "y=tf.Variable(4,name=\"y\")\n",
    "f = x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(3)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y , z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype = tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.transpose(tf.matmul(XT,X)),XT),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7855876e+15]\n",
      " [ 6.9242926e+15]\n",
      " [ 4.5896974e+16]\n",
      " [ 9.4425232e+15]\n",
      " [ 1.9140634e+15]\n",
      " [ 4.1384996e+18]\n",
      " [ 6.5041251e+15]\n",
      " [ 6.3297437e+16]\n",
      " [-2.1322162e+17]]\n"
     ]
    }
   ],
   "source": [
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "          37.88      , -122.23      ],\n",
       "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "          37.86      , -122.22      ],\n",
       "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "          37.85      , -122.24      ],\n",
       "       ...,\n",
       "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "          39.43      , -121.22      ],\n",
       "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "          39.43      , -121.32      ],\n",
       "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "          39.37      , -121.24      ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_housing_data = scaler.fit_transform(housing.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_housing_data_plus_bias = np.c_[np.ones((m,1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  11.787323\n",
      "Epoch 100 MSE =  0.8123056\n",
      "Epoch 200 MSE =  0.6169669\n",
      "Epoch 300 MSE =  0.58968\n",
      "Epoch 400 MSE =  0.5718467\n",
      "Epoch 500 MSE =  0.5589477\n",
      "Epoch 600 MSE =  0.5495861\n",
      "Epoch 700 MSE =  0.5427859\n",
      "Epoch 800 MSE =  0.53784084\n",
      "Epoch 900 MSE =  0.5342403\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X),error)\n",
    "training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  12.352856\n",
      "Epoch 100 MSE =  0.8791998\n",
      "Epoch 200 MSE =  0.67444366\n",
      "Epoch 300 MSE =  0.63200426\n",
      "Epoch 400 MSE =  0.6031126\n",
      "Epoch 500 MSE =  0.58212656\n",
      "Epoch 600 MSE =  0.56682765\n",
      "Epoch 700 MSE =  0.55565685\n",
      "Epoch 800 MSE =  0.54748726\n",
      "Epoch 900 MSE =  0.54150057\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "gradients = tf.gradients(mse,[theta])[0]\n",
    "training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  9.353131\n",
      "Epoch 100 MSE =  0.59290034\n",
      "Epoch 200 MSE =  0.55875313\n",
      "Epoch 300 MSE =  0.5422296\n",
      "Epoch 400 MSE =  0.5336369\n",
      "Epoch 500 MSE =  0.5291674\n",
      "Epoch 600 MSE =  0.52684337\n",
      "Epoch 700 MSE =  0.5256333\n",
      "Epoch 800 MSE =  0.5250045\n",
      "Epoch 900 MSE =  0.5246768\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.02\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "#gradients = 2/m*tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  12.759729\n",
      "Epoch 100 MSE =  0.61546487\n",
      "Epoch 200 MSE =  0.5580961\n",
      "Epoch 300 MSE =  0.53786886\n",
      "Epoch 400 MSE =  0.5301127\n",
      "Epoch 500 MSE =  0.5269115\n",
      "Epoch 600 MSE =  0.52551335\n",
      "Epoch 700 MSE =  0.52488\n",
      "Epoch 800 MSE =  0.5245856\n",
      "Epoch 900 MSE =  0.524447\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.02\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "#gradients = 2/m*tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  9.944074\n",
      "Epoch 0 MSE =  6.6608715\n",
      "Epoch 0 MSE =  6.58721\n",
      "Epoch 0 MSE =  4.67568\n",
      "Epoch 0 MSE =  3.4896116\n",
      "Epoch 0 MSE =  2.3729491\n",
      "Epoch 0 MSE =  1.6959649\n",
      "Epoch 0 MSE =  0.6418256\n",
      "Epoch 0 MSE =  0.9764943\n",
      "Epoch 0 MSE =  1.113908\n",
      "Epoch 0 MSE =  1.4226879\n",
      "Epoch 0 MSE =  1.7158768\n",
      "Epoch 0 MSE =  1.9747684\n",
      "Epoch 0 MSE =  2.2827945\n",
      "Epoch 0 MSE =  2.3659618\n",
      "Epoch 0 MSE =  2.4971879\n",
      "Epoch 0 MSE =  2.1713016\n",
      "Epoch 0 MSE =  1.9831624\n",
      "Epoch 0 MSE =  1.9019834\n",
      "Epoch 0 MSE =  1.52013\n",
      "Epoch 0 MSE =  1.1939\n",
      "Epoch 0 MSE =  0.9241339\n",
      "Epoch 0 MSE =  0.84015566\n",
      "Epoch 0 MSE =  0.7687517\n",
      "Epoch 0 MSE =  0.5614379\n",
      "Epoch 0 MSE =  0.96447736\n",
      "Epoch 0 MSE =  0.7301999\n",
      "Epoch 0 MSE =  0.76379657\n",
      "Epoch 0 MSE =  0.8083755\n",
      "Epoch 0 MSE =  1.1039398\n",
      "Epoch 0 MSE =  0.70757943\n",
      "Epoch 0 MSE =  0.8561192\n",
      "Epoch 0 MSE =  0.7717528\n",
      "Epoch 0 MSE =  0.5260902\n",
      "Epoch 0 MSE =  1.1716636\n",
      "Epoch 0 MSE =  0.6758223\n",
      "Epoch 0 MSE =  0.81509215\n",
      "Epoch 0 MSE =  0.626141\n",
      "Epoch 0 MSE =  0.64240575\n",
      "Epoch 0 MSE =  0.5668855\n",
      "Epoch 0 MSE =  0.59448916\n",
      "Epoch 0 MSE =  0.50553393\n",
      "Epoch 0 MSE =  0.59324133\n",
      "Epoch 0 MSE =  0.6189521\n",
      "Epoch 0 MSE =  0.6948079\n",
      "Epoch 0 MSE =  0.4660244\n",
      "Epoch 0 MSE =  0.72934425\n",
      "Epoch 0 MSE =  0.5109622\n",
      "Epoch 0 MSE =  0.5785575\n",
      "Epoch 0 MSE =  0.4623211\n",
      "Epoch 0 MSE =  0.43659154\n",
      "Epoch 0 MSE =  0.69577044\n",
      "Epoch 0 MSE =  0.47830546\n",
      "Epoch 0 MSE =  0.5697398\n",
      "Epoch 0 MSE =  0.51945466\n",
      "Epoch 0 MSE =  0.48742267\n",
      "Epoch 0 MSE =  0.31820574\n",
      "Epoch 0 MSE =  0.5169587\n",
      "Epoch 0 MSE =  0.8342372\n",
      "Epoch 0 MSE =  0.6175373\n",
      "Epoch 0 MSE =  0.50198644\n",
      "Epoch 0 MSE =  0.59676033\n",
      "Epoch 0 MSE =  0.35349098\n",
      "Epoch 0 MSE =  0.45455077\n",
      "Epoch 0 MSE =  0.66751295\n",
      "Epoch 0 MSE =  0.7548394\n",
      "Epoch 0 MSE =  0.54614365\n",
      "Epoch 0 MSE =  0.47197488\n",
      "Epoch 0 MSE =  0.51125574\n",
      "Epoch 0 MSE =  0.55750155\n",
      "Epoch 0 MSE =  0.43108636\n",
      "Epoch 0 MSE =  0.7401753\n",
      "Epoch 0 MSE =  0.49906537\n",
      "Epoch 0 MSE =  0.755092\n",
      "Epoch 0 MSE =  0.7468417\n",
      "Epoch 0 MSE =  0.56757164\n",
      "Epoch 0 MSE =  0.71977586\n",
      "Epoch 0 MSE =  0.6368048\n",
      "Epoch 0 MSE =  0.4882275\n",
      "Epoch 0 MSE =  0.54219985\n",
      "Epoch 0 MSE =  0.61087954\n",
      "Epoch 0 MSE =  0.42996207\n",
      "Epoch 0 MSE =  0.3614892\n",
      "Epoch 0 MSE =  0.59441763\n",
      "Epoch 0 MSE =  0.97831553\n",
      "Epoch 0 MSE =  0.46341884\n",
      "Epoch 0 MSE =  0.5139526\n",
      "Epoch 0 MSE =  0.54742163\n",
      "Epoch 0 MSE =  0.59774697\n",
      "Epoch 0 MSE =  0.5884313\n",
      "Epoch 0 MSE =  0.62384856\n",
      "Epoch 0 MSE =  0.69860214\n",
      "Epoch 0 MSE =  0.83635134\n",
      "Epoch 0 MSE =  0.5390619\n",
      "Epoch 0 MSE =  0.58487093\n",
      "Epoch 0 MSE =  0.6856992\n",
      "Epoch 0 MSE =  0.43536255\n",
      "Epoch 0 MSE =  0.56789786\n",
      "Epoch 0 MSE =  0.7029497\n",
      "Epoch 0 MSE =  0.7192465\n",
      "Epoch 0 MSE =  0.6399066\n",
      "Epoch 0 MSE =  0.76011693\n",
      "Epoch 0 MSE =  0.62092865\n",
      "Epoch 0 MSE =  14.694266\n",
      "Epoch 0 MSE =  0.55213076\n",
      "Epoch 0 MSE =  0.6362789\n",
      "Epoch 0 MSE =  0.7581729\n",
      "Epoch 0 MSE =  0.6752568\n",
      "Epoch 0 MSE =  0.68122864\n",
      "Epoch 0 MSE =  0.6111714\n",
      "Epoch 0 MSE =  0.984\n",
      "Epoch 0 MSE =  1.0607047\n",
      "Epoch 0 MSE =  0.68705124\n",
      "Epoch 0 MSE =  0.4496875\n",
      "Epoch 0 MSE =  0.72976524\n",
      "Epoch 0 MSE =  0.6063861\n",
      "Epoch 0 MSE =  0.45497623\n",
      "Epoch 0 MSE =  4.4328322\n",
      "Epoch 0 MSE =  0.5935064\n",
      "Epoch 0 MSE =  0.45140836\n",
      "Epoch 0 MSE =  0.46088192\n",
      "Epoch 0 MSE =  0.48730427\n",
      "Epoch 0 MSE =  0.451538\n",
      "Epoch 0 MSE =  0.41596103\n",
      "Epoch 0 MSE =  0.4449753\n",
      "Epoch 0 MSE =  0.32893288\n",
      "Epoch 0 MSE =  0.6005104\n",
      "Epoch 0 MSE =  0.4031562\n",
      "Epoch 0 MSE =  0.39818573\n",
      "Epoch 0 MSE =  0.651192\n",
      "Epoch 0 MSE =  0.5667372\n",
      "Epoch 0 MSE =  0.52567375\n",
      "Epoch 0 MSE =  0.5927054\n",
      "Epoch 0 MSE =  0.6962564\n",
      "Epoch 0 MSE =  0.54440016\n",
      "Epoch 0 MSE =  0.49308312\n",
      "Epoch 0 MSE =  0.686522\n",
      "Epoch 0 MSE =  0.4523796\n",
      "Epoch 0 MSE =  0.6303837\n",
      "Epoch 0 MSE =  0.47413555\n",
      "Epoch 0 MSE =  0.32587197\n",
      "Epoch 0 MSE =  0.43598583\n",
      "Epoch 0 MSE =  0.42047942\n",
      "Epoch 0 MSE =  0.4546458\n",
      "Epoch 0 MSE =  0.54372424\n",
      "Epoch 0 MSE =  0.61224294\n",
      "Epoch 0 MSE =  0.8295569\n",
      "Epoch 0 MSE =  0.51526755\n",
      "Epoch 0 MSE =  0.35559997\n",
      "Epoch 0 MSE =  0.58034796\n",
      "Epoch 0 MSE =  0.52213115\n",
      "Epoch 0 MSE =  0.6141252\n",
      "Epoch 0 MSE =  0.6101177\n",
      "Epoch 0 MSE =  0.5677936\n",
      "Epoch 0 MSE =  0.5282126\n",
      "Epoch 0 MSE =  0.6026715\n",
      "Epoch 0 MSE =  0.5210258\n",
      "Epoch 0 MSE =  0.42228252\n",
      "Epoch 0 MSE =  0.5917524\n",
      "Epoch 0 MSE =  0.5352092\n",
      "Epoch 0 MSE =  0.47479057\n",
      "Epoch 0 MSE =  0.43223703\n",
      "Epoch 0 MSE =  0.7976753\n",
      "Epoch 0 MSE =  0.73822707\n",
      "Epoch 0 MSE =  0.87201357\n",
      "Epoch 0 MSE =  0.42408025\n",
      "Epoch 0 MSE =  0.49562398\n",
      "Epoch 0 MSE =  0.49203637\n",
      "Epoch 0 MSE =  0.5025182\n",
      "Epoch 0 MSE =  0.32855693\n",
      "Epoch 0 MSE =  0.3868827\n",
      "Epoch 0 MSE =  0.5668902\n",
      "Epoch 0 MSE =  0.518844\n",
      "Epoch 0 MSE =  0.43084878\n",
      "Epoch 0 MSE =  0.5895538\n",
      "Epoch 0 MSE =  0.44980472\n",
      "Epoch 0 MSE =  0.4539882\n",
      "Epoch 0 MSE =  0.51129466\n",
      "Epoch 0 MSE =  0.40860912\n",
      "Epoch 0 MSE =  0.3459207\n",
      "Epoch 0 MSE =  0.7769852\n",
      "Epoch 0 MSE =  0.62589693\n",
      "Epoch 0 MSE =  0.40698716\n",
      "Epoch 0 MSE =  0.5059643\n",
      "Epoch 0 MSE =  0.6990379\n",
      "Epoch 0 MSE =  0.57827955\n",
      "Epoch 0 MSE =  0.5270224\n",
      "Epoch 0 MSE =  0.6301967\n",
      "Epoch 0 MSE =  0.6926162\n",
      "Epoch 0 MSE =  0.57585585\n",
      "Epoch 0 MSE =  0.4520742\n",
      "Epoch 0 MSE =  0.39307576\n",
      "Epoch 0 MSE =  0.5468834\n",
      "Epoch 0 MSE =  0.59885633\n",
      "Epoch 0 MSE =  0.61921716\n",
      "Epoch 0 MSE =  0.47260702\n",
      "Epoch 0 MSE =  0.70243126\n",
      "Epoch 0 MSE =  0.54634094\n",
      "Epoch 0 MSE =  0.68153054\n",
      "Epoch 0 MSE =  0.6728337\n",
      "Epoch 0 MSE =  0.47698456\n",
      "Epoch 0 MSE =  0.52666485\n",
      "Epoch 0 MSE =  0.73199075\n",
      "Epoch 0 MSE =  0.52530545\n",
      "Epoch 0 MSE =  0.565248\n",
      "Epoch 0 MSE =  0.37164283\n",
      "Epoch 0 MSE =  0.4788753\n"
     ]
    }
   ],
   "source": [
    "z = housing.target.reshape(-1,1)\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = \"y\")\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.02\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch,y: y_batch})\n",
    "            if epoch%100 == 0:\n",
    "                print(\"Epoch\",epoch,\"MSE = \",sess.run(mse,feed_dict={X: X_batch,y: y_batch}))\n",
    "    best_theta = theta.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  9.33558\n",
      "Epoch 100 MSE =  0.5746847\n",
      "Epoch 200 MSE =  0.5403007\n",
      "Epoch 300 MSE =  0.52979964\n",
      "Epoch 400 MSE =  0.5263648\n",
      "Epoch 500 MSE =  0.52514565\n",
      "Epoch 600 MSE =  0.5246748\n",
      "Epoch 700 MSE =  0.52448004\n",
      "Epoch 800 MSE =  0.524394\n",
      "Epoch 900 MSE =  0.5243555\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.02\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "#gradients = 2/m*tf.matmul(tf.transpose(X),error)\n",
    "#training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess,\"/tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n",
      "Epoch 0 MSE =  0.5243369\n",
      "Epoch 100 MSE =  0.5243281\n",
      "Epoch 200 MSE =  0.5243247\n",
      "Epoch 300 MSE =  0.52432245\n",
      "Epoch 400 MSE =  0.5243221\n",
      "Epoch 500 MSE =  0.52432096\n",
      "Epoch 600 MSE =  0.52432054\n",
      "Epoch 700 MSE =  0.524321\n",
      "Epoch 800 MSE =  0.52432114\n",
      "Epoch 900 MSE =  0.52432126\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"/tmp/my_model_final.ckpt\")\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n",
      "Epoch 0 MSE =  0.5243369\n",
      "Epoch 100 MSE =  0.5243281\n",
      "Epoch 200 MSE =  0.5243247\n",
      "Epoch 300 MSE =  0.52432245\n",
      "Epoch 400 MSE =  0.5243221\n",
      "Epoch 500 MSE =  0.52432096\n",
      "Epoch 600 MSE =  0.52432054\n",
      "Epoch 700 MSE =  0.524321\n",
      "Epoch 800 MSE =  0.52432114\n",
      "Epoch 900 MSE =  0.52432126\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"/tmp/my_model_final.ckpt\")\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
    "        sess.run(training_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir,now)\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.02\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.5)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE',mse)\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\",epoch,\"MSE = \",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir,now)\n",
    "X = tf.placeholder(tf.float32, shape = (None, n + 1), name = \"X\")\n",
    "y = tf.placeholder(tf.float32, shape = (None, 1), name = \"y\")\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1],-1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X,theta,name = 'predictions')\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error), name = \"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE',mse)\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index%10==0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "                step = epoch*n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str,step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch,y: y_batch})\n",
    "    file_writer.close()\n",
    "    best_theta = theta.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval() \n",
    "file_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval() \n",
    "file_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]),1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "    b = tf.Variable(0.0,name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "    return tf.maximum(z, 0.0, name=\"relu\")\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_features), name = \"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu1\",tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\") as scope:\n",
    "        w_shape = (int(X.get_shape()[1]),1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "        b = tf.Variable(0.0,name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "        return tf.maximum(z, 0.0, name=\"relu\")\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_features), name = \"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu2\",tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\",reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = (int(X.get_shape()[1]),1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "        b = tf.Variable(0.0,name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"relu\")\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_features), name = \"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\",shape=(),initializer = tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu4\",tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\",shape=(),initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]),1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape),name=\"weights\")\n",
    "    b = tf.Variable(0.0,name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "    return tf.maximum(z, threshold, name=\"relu\")\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_features), name = \"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\",reuse=(relu_index>=1)):\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu5\",tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
